{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_range = np.arange(80, 112000, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_indeces = np.load('src/time_train_indeces.npy')\n",
    "validation_indeces = np.load('src/time_validation_indeces.npy')\n",
    "test_indeces = np.load('src/time_test_indeces.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = M_star = 5\n",
    "N = NUMBER_OF_PEDESTRIANS\n",
    "X = Y = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "location = np.load('src/pedestrians_location.npy') # [NUMBER_OF_PEDESTRIANS x NUMBER_OF_FRAMES x 2]\n",
    "location[:,:,0] = (X * location[:,:,0] / FRAME_WIDTH).astype(np.int64)\n",
    "location[:,:,1] = (Y * location[:,:,1] / FRAME_HEIGHT).astype(np.int64)\n",
    "# location[i,t] = [x,y] -- location of i-th pedestrian at time point t (aka frame 20*t) -- [0,0] for absent pedestians\n",
    "\n",
    "ped_paths = np.load('src/all_not_ext_paths_with_ids.npy')\n",
    "# ped_paths[j] = [i,t,x,y] -- all pedestrians' coordinates at all frames\n",
    "ped_paths[:,2] = (X * ped_paths[:,2] / FRAME_WIDTH).astype(np.int64)\n",
    "ped_paths[:,3] = (Y * ped_paths[:,3] / FRAME_HEIGHT).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# M-1 time points before curr_time and M_star after\n",
    "def get_t(curr_time, M, M_star):\n",
    "    step = 20\n",
    "    return np.arange(curr_time - step*(M-1), curr_time + step*(M_star+1), step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_cuda(arr):\n",
    "    return Variable(torch.from_numpy(arr).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "    \n",
    "        self.conv1 = nn.Conv3d(in_channels=1, out_channels=64, kernel_size=(2*M, 3, 3), bias=False)\n",
    "        self.conv2 = nn.Conv3d(in_channels=64, out_channels=64, kernel_size=(1, 3, 3), padding=(0, 1, 1), bias=False)\n",
    "        self.conv3 = nn.Conv3d(in_channels=64, out_channels=64, kernel_size=(1, 3, 3), padding=(0, 1, 1), bias=False)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "        \n",
    "        self.bias_map = Parameter(torch.rand(int((X-1)/2), int((Y-1)/2)))\n",
    "        \n",
    "        self.conv4 = nn.Conv3d(in_channels=64, out_channels=64, kernel_size=(1, 3, 3), padding=(0, 1, 1), bias=False)\n",
    "        self.conv5 = nn.Conv3d(in_channels=64, out_channels=64, kernel_size=(1, 3, 3), padding=(0, 1, 1), bias=False)\n",
    "        self.conv6 = nn.Conv3d(in_channels=64, out_channels=64, kernel_size=(1, 3, 3), padding=(0, 1, 1), bias=False)\n",
    "        \n",
    "        self.deconv = nn.ConvTranspose3d(in_channels=64, out_channels=1, kernel_size=(2*M_star, 4, 4), stride=(1, 2, 2),\n",
    "                                         bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = x + self.bias_map.unsqueeze(0).expand_as(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        \n",
    "        x = self.deconv(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "model = Net()\n",
    "model = model.double()\n",
    "model.cuda()\n",
    "\n",
    "criterion = nn.MSELoss(size_average=False).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "fails = []\n",
    "train_losses = []\n",
    "validation_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_indeces = train_indeces[:3200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_arrays(indeces):\n",
    "    \n",
    "    dv = np.zeros((0, X, Y, 2*M))\n",
    "    dv_star = np.zeros((0, X, Y, 2*M_star))\n",
    "    m = np.zeros((0, X, Y, 2*M))\n",
    "\n",
    "    for curr_time in time_range[indeces]:\n",
    "        \n",
    "        t = get_t(curr_time, M, M_star)\n",
    "        ind_t = (t/20).astype(int) # for indexing in location\n",
    "\n",
    "        pedestrians_in_scene = ped_paths[ped_paths[:,1] == t[M-1]] # getting all pedestrians who located on map at curr_time\n",
    "\n",
    "        disp_volume = np.zeros((X, Y, 2*M))\n",
    "        disp_volume_star = np.zeros((X, Y, 2*M_star))\n",
    "\n",
    "        for p in pedestrians_in_scene:\n",
    "            l = location[p[0],ind_t[:M]] # locations of pedestrian at t_1, t_2, ..., t_M time points\n",
    "            l_star = location[p[0],ind_t[M:]]\n",
    "\n",
    "            # filling zeros absent pedestrians\n",
    "            for i, row in enumerate(l):\n",
    "                if (row == 0).all():\n",
    "                    l[i] = l[-1] + np.array([X, Y]) # to get zero in displacement vector\n",
    "\n",
    "            for i, row in enumerate(l_star):\n",
    "                if (row == 0).all():\n",
    "                    l_star[i] = l_star[-1] + np.array([X, Y])\n",
    "\n",
    "            d = (l[-1] - l) / np.array([X, Y]) + 1\n",
    "            d_star = (l_star[-1] - l_star) / np.array([X, Y]) + 1\n",
    "            disp_volume[p[2], p[3]] = d.ravel() # put in [X, Y]-th cell of disp_volume displacement vector\n",
    "            disp_volume_star[location[p[0],ind_t[-1]][0], location[p[0],ind_t[-1]][1]] = d_star.ravel()    \n",
    "\n",
    "        mask = (disp_volume_star != 0).astype(int)\n",
    "\n",
    "        dv = np.concatenate((dv, [disp_volume]))\n",
    "        dv_star = np.concatenate((dv_star, [disp_volume_star]))\n",
    "        m = np.concatenate((m, [mask]))\n",
    "\n",
    "    dv = np.transpose(dv, axes=(0,3,1,2))\n",
    "    dv_star = np.transpose(dv_star, axes=(0,3,1,2))\n",
    "    m = np.transpose(m, axes=(0,3,1,2))\n",
    "\n",
    "    dv = dv[:, np.newaxis]\n",
    "    dv_star = dv_star[:, np.newaxis]\n",
    "    m = m[:, np.newaxis]\n",
    "    sum_m = m.sum(axis=-1).sum(axis=-1).sum(axis=-1).sum(axis=-1)\n",
    "    \n",
    "    return dv, dv_star, m, sum_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/401 [00:02<05:16,  1.26it/s]"
     ]
    }
   ],
   "source": [
    "for it in range(100):\n",
    "\n",
    "    for i in tqdm(range(ceil(len(train_indeces) / batch_size) + 1)):\n",
    "\n",
    "        dv, dv_star, m, sum_m = get_arrays(train_indeces[i * batch_size : (i+1) * batch_size])\n",
    "\n",
    "        try:\n",
    "            pred = model(to_cuda(dv))\n",
    "            sum_m_cuda = to_cuda(sum_m).unsqueeze(1).unsqueeze(1).unsqueeze(1).unsqueeze(1).expand_as(pred).double()\n",
    "            loss = criterion(pred * to_cuda(m) / sum_m_cuda, to_cuda(dv_star) / sum_m_cuda)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        except:\n",
    "            fails.append(i)\n",
    "            continue\n",
    "            \n",
    "    train_loss = 0\n",
    "\n",
    "    for i in tqdm(range(ceil(len(train_indeces) / batch_size) + 1)):\n",
    "\n",
    "        dv, dv_star, m, sum_m = get_arrays(train_indeces[i * batch_size : (i+1) * batch_size])\n",
    "\n",
    "        try:\n",
    "            pred = model(to_cuda(dv))\n",
    "            sum_m_cuda = to_cuda(sum_m).unsqueeze(1).unsqueeze(1).unsqueeze(1).unsqueeze(1).expand_as(pred).double()\n",
    "            loss = criterion(pred * to_cuda(m) / sum_m_cuda, to_cuda(dv_star) / sum_m_cuda)\n",
    "            train_loss = (train_loss * i + loss.data.cpu()) / (i + 1)\n",
    "        except:\n",
    "            fails.append(i)\n",
    "            continue\n",
    "            \n",
    "    train_losses.append(train_loss)\n",
    "            \n",
    "    validation_loss_prev = validation_losses[-1]\n",
    "    validation_loss = 0\n",
    "\n",
    "    for i in tqdm(range(ceil(len(validation_indeces) / batch_size) + 1)):\n",
    "\n",
    "        dv, dv_star, m, sum_m = get_arrays(train_indeces[i * batch_size : (i+1) * batch_size])\n",
    "\n",
    "        try:\n",
    "            pred = model(to_cuda(dv))\n",
    "            sum_m_cuda = to_cuda(sum_m).unsqueeze(1).unsqueeze(1).unsqueeze(1).unsqueeze(1).expand_as(pred).double()\n",
    "            loss = criterion(pred * to_cuda(m) / sum_m_cuda, to_cuda(dv_star) / sum_m_cuda)\n",
    "            validation_loss = (validation_loss * i + loss.data.cpu()) / (i + 1)\n",
    "        except:\n",
    "            fails.append(i)\n",
    "            continue\n",
    "            \n",
    "    validation_losses.append(validation_loss)\n",
    "    \n",
    "    if validation_loss_prev[0] < validation_loss[0]:\n",
    "        validation_losses.append(validation_loss)\n",
    "        break\n",
    "    \n",
    "    print(train_loss, validation_loss)\n",
    "    \n",
    "    torch.save(model.state_dict(), 'src/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('src/model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# THERE IS A PROBLEM HERE:\n",
    "# we lose pedestrians' ids after coding into disp_volume so to decode we need somehow match previous path and predicted\n",
    "\n",
    "# displacement volume decode\n",
    "xs, ys = disp_volume[:,:,0].nonzero() # getting indices of non-zero predicted coordinates at first (t_M+1) timepoint\n",
    "for i, j in zip(xs,ys):\n",
    "    np.array([i,j]) - (disp_volume[i,j].reshape(-1,2) - 1) * np.array([X, Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " 1.00000e-04 *\n",
       "   5.1165\n",
       " [torch.DoubleTensor of size 1], \n",
       " 1.00000e-04 *\n",
       "   5.1162\n",
       " [torch.DoubleTensor of size 1], \n",
       " 1.00000e-04 *\n",
       "   5.1159\n",
       " [torch.DoubleTensor of size 1], \n",
       " 1.00000e-04 *\n",
       "   5.1156\n",
       " [torch.DoubleTensor of size 1], \n",
       " 1.00000e-04 *\n",
       "   5.1153\n",
       " [torch.DoubleTensor of size 1], \n",
       " 1.00000e-04 *\n",
       "   5.1150\n",
       " [torch.DoubleTensor of size 1], \n",
       " 1.00000e-04 *\n",
       "   5.1148\n",
       " [torch.DoubleTensor of size 1], \n",
       " 1.00000e-04 *\n",
       "   5.1145\n",
       " [torch.DoubleTensor of size 1], \n",
       " 1.00000e-04 *\n",
       "   5.1142\n",
       " [torch.DoubleTensor of size 1], \n",
       " 1.00000e-04 *\n",
       "   5.1139\n",
       " [torch.DoubleTensor of size 1]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_losses[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
