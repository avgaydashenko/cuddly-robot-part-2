{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lutorpy as lua\n",
    "require(\"nn\")\n",
    "require(\"optim\")\n",
    "require(\"cutorch\")\n",
    "require(\"cunn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = M_star = 5\n",
    "N = NUMBER_OF_PEDESTRIANS\n",
    "X = Y = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location = np.load('src/pedestrians_location.npy') # [NUMBER_OF_PEDESTRIANS x NUMBER_OF_FRAMES x 2]\n",
    "location[:,:,0] = (location[:,:,0] / X).astype(np.int64)\n",
    "location[:,:,1] = (location[:,:,1] / Y).astype(np.int64)\n",
    "# location[i,t] = [x,y] -- location of i-th pedestrian at time point t (aka frame 20*t) -- [0,0] for absent pedestians\n",
    "\n",
    "paths = np.load('src/all_not_ext_paths_with_ids.npy') # paths[j] = [i,t,x,y] -- all pedestrians' coordinates at all frames\n",
    "paths[:,2] = (paths[:,2] / X).astype(np.int64)\n",
    "paths[:,3] = (paths[:,3] / Y).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# M-1 time points before curr_time and M_star after\n",
    "def get_t(curr_time, M, M_star):\n",
    "    step = 20\n",
    "    return np.arange(curr_time - step*(M-1), curr_time + step*(M_star+1), step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 20,  40,  60,  80, 100, 120, 140, 160, 180, 200])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = get_t(100, M, M_star)\n",
    "ind_t = (t/20).astype(int) # for indexing in location\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pedestrians_in_scene = paths[paths[:,1] == t[M-1]] # getting all pedestrians who located on map at curr_time\n",
    "\n",
    "disp_volume = np.zeros((X, Y, 2*M))\n",
    "disp_volume_star = np.zeros((X, Y, 2*M_star))\n",
    "\n",
    "for p in pedestrians_in_scene:\n",
    "    l = location[p[0],ind_t[:M]] # locations of pedestrian at t_1, t_2, ..., t_M time points\n",
    "    l_star = location[p[0],ind_t[M:]]\n",
    "    \n",
    "    # filling zeros absent pedestrians\n",
    "    for i, row in enumerate(l):\n",
    "        if (row == 0).all():\n",
    "            l_star[i] = l_star[-1] + np.array([X, Y])\n",
    "            l[i] = l[-1] + np.array([X, Y]) # to get zero after next code line\n",
    "            \n",
    "    d = (l[-1] - l) / np.array([X, Y]) + 1\n",
    "    d_star = (l_star[-1] - l) / np.array([X, Y]) + 1\n",
    "    disp_volume[p[2], p[3]] = d.ravel() # put in [X, Y]-th cell of disp_volume displacement vector\n",
    "    disp_volume_star[location[p[0],ind_t[-1]][0], location[p[0],ind_t[-1]][1]] = d_star.ravel()    \n",
    "    \n",
    "mask = (disp_volume_star != 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# THERE IS A PROBLEM HERE:\n",
    "# we lose pedestrians' ids after coding into disp_volume so to decode we need somehow match previous path and predicted\n",
    "\n",
    "# displacement volume decode\n",
    "xs, ys = disp_volume[:,:,0].nonzero() # getting indices of non-zero predicted coordinates at first (t_M+1) timepoint\n",
    "for i, j in zip(xs,ys):\n",
    "    np.array([i,j]) - (disp_volume[i,j].reshape(-1,2) - 1) * np.array([X, Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "\n",
    "filters_num = 64\n",
    "kW = kH = 3\n",
    "padW = padH = 1\n",
    "\n",
    "# https://github.com/torch/nn/blob/master/doc/convolution.md#nn.SpatialConvolution\n",
    "model._add(nn.SpatialConvolution(2*M, filters_num, kW, kH, 1, 1, padW, padH)) # conv1\n",
    "model._add(nn.SpatialConvolution(filters_num, filters_num, kW, kH, 1, 1, padW, padH)) # conv2\n",
    "model._add(nn.SpatialConvolution(filters_num, filters_num, kW, kH, 1, 1, padW, padH)) # conv3\n",
    "\n",
    "# https://github.com/torch/nn/blob/master/doc/convolution.md#nn.SpatialMaxPooling\n",
    "model._add(nn.SpatialMaxPooling(2, 2, 2, 2))\n",
    "\n",
    "# https://github.com/torch/nn/blob/master/doc/simple.md#nn.CAdd\n",
    "model._add(nn.CAdd(1, int(Y/2), int(X/2))) # bias\n",
    "\n",
    "model._add(nn.SpatialConvolution(filters_num, filters_num, kW, kH, 1, 1, padW, padH)) # conv4\n",
    "model._add(nn.SpatialConvolution(filters_num, filters_num, kW, kH, 1, 1, padW, padH)) # conv5\n",
    "model._add(nn.SpatialConvolution(filters_num, 2*M_star, kW, kH, 1, 1, padW, padH)) # conv6\n",
    "\n",
    "# https://github.com/torch/nn/blob/master/doc/convolution.md#spatialfullconvolution\n",
    "model._add(nn.SpatialFullConvolution(2*M_star, 2*M_star, 4, 4, 2, 2)) # deconv\n",
    "\n",
    "criterion = nn.MSECriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def from_numpy(array):\n",
    "    return torch.fromNumpyArray(array.T)\n",
    "\n",
    "def to_numpy(array):\n",
    "    return (array.asNumpyArray()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LuaError",
     "evalue": "...gaydashenko/torch/install/share/lua/5.1/nn/Container.lua:67: \nIn 9 module of nn.Sequential:\n/home/gaydashenko/torch/install/share/lua/5.1/nn/THNN.lua:110: Need gradOutput of dimension 3 and gradOutput.size[1] == 258 but got gradOutput to be of shape: [10 x 256 x 256] at /home/gaydashenko/torch/extra/nn/lib/THNN/generic/SpatialFullConvolution.c:106\nstack traceback:\n\t[C]: in function 'v'\n\t/home/gaydashenko/torch/install/share/lua/5.1/nn/THNN.lua:110: in function 'SpatialFullConvolution_updateGradInput'\n\t...orch/install/share/lua/5.1/nn/SpatialFullConvolution.lua:148: in function 'updateGradInput'\n\t/home/gaydashenko/torch/install/share/lua/5.1/nn/Module.lua:31: in function </home/gaydashenko/torch/install/share/lua/5.1/nn/Module.lua:29>\n\t[C]: in function 'xpcall'\n\t...gaydashenko/torch/install/share/lua/5.1/nn/Container.lua:63: in function 'rethrowErrors'\n\t...aydashenko/torch/install/share/lua/5.1/nn/Sequential.lua:84: in function <...aydashenko/torch/install/share/lua/5.1/nn/Sequential.lua:78>\n\nWARNING: If you see a stack trace below, it doesn't point to the place where this error occurred. Please use only the one above.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLuaError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-99723bdf75c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp_volume_star\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_zeroGradParameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp_volume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp_volume_star\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upgradeParameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mlutorpy/_lupa.pyx\u001b[0m in \u001b[0;36mlutorpy._lupa._LuaObject.__getattr__.self_prepending_function (lutorpy/_lupa.c:10774)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mlutorpy/_lupa.pyx\u001b[0m in \u001b[0;36mlutorpy._lupa._LuaObject.__call__ (lutorpy/_lupa.c:9459)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mlutorpy/_lupa.pyx\u001b[0m in \u001b[0;36mlutorpy._lupa.call_lua (lutorpy/_lupa.c:25877)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mlutorpy/_lupa.pyx\u001b[0m in \u001b[0;36mlutorpy._lupa.execute_lua_call (lutorpy/_lupa.c:25987)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mlutorpy/_lupa.pyx\u001b[0m in \u001b[0;36mlutorpy._lupa.raise_lua_error (lutorpy/_lupa.c:25297)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mLuaError\u001b[0m: ...gaydashenko/torch/install/share/lua/5.1/nn/Container.lua:67: \nIn 9 module of nn.Sequential:\n/home/gaydashenko/torch/install/share/lua/5.1/nn/THNN.lua:110: Need gradOutput of dimension 3 and gradOutput.size[1] == 258 but got gradOutput to be of shape: [10 x 256 x 256] at /home/gaydashenko/torch/extra/nn/lib/THNN/generic/SpatialFullConvolution.c:106\nstack traceback:\n\t[C]: in function 'v'\n\t/home/gaydashenko/torch/install/share/lua/5.1/nn/THNN.lua:110: in function 'SpatialFullConvolution_updateGradInput'\n\t...orch/install/share/lua/5.1/nn/SpatialFullConvolution.lua:148: in function 'updateGradInput'\n\t/home/gaydashenko/torch/install/share/lua/5.1/nn/Module.lua:31: in function </home/gaydashenko/torch/install/share/lua/5.1/nn/Module.lua:29>\n\t[C]: in function 'xpcall'\n\t...gaydashenko/torch/install/share/lua/5.1/nn/Container.lua:63: in function 'rethrowErrors'\n\t...aydashenko/torch/install/share/lua/5.1/nn/Sequential.lua:84: in function <...aydashenko/torch/install/share/lua/5.1/nn/Sequential.lua:78>\n\nWARNING: If you see a stack trace below, it doesn't point to the place where this error occurred. Please use only the one above."
     ]
    }
   ],
   "source": [
    "pred = to_numpy(model._forward(from_numpy(disp_volume)))[1:-1, 1:-1]\n",
    "criterion._forward(from_numpy(pred*mask), from_numpy(disp_volume_star))\n",
    "model._zeroGradParameters()\n",
    "model._backward(from_numpy(disp_volume), criterion._backward(from_numpy(pred*mask), from_numpy(disp_volume_star)))\n",
    "model._upgradeParameters(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
